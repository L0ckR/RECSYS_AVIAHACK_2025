# Архитектуры рекомендательных систем для

# ПСБ на основе T-ECD

**Введение.** Банк ПСБ планирует внедрить современную рекомендательную систему, используя
богатый массив данных о клиентах. Согласно техническому заданию AI Challenge: Banking, целью
является **персонализация предложений** банковских продуктов для повышения их
релевантности и конверсии. Данные предоставляются в виде крупномасштабного набора T-
ECD, содержащего ≈44 млн анонимных пользователей и >135 млрд взаимодействий. Этот
датасет охватывает несколько доменов – маркетплейс (e-commerce), ритейл-доставку, платежи,
отклик на рекламные офферы и отзывы. Такая кросс-доменная структура позволяет
связать разные аспекты поведения клиента в едином профиле и решать разнообразные задачи
рекомендаций , включая Next Best Offer, кросс-продажи, next-item рекомендации и т.д.

Ниже рассмотрены **две вариации архитектуры** рекомендательной системы для банка:
полностью **персонализированные рекомендации** для каждого клиента и рекомендации на
основе **сегментов клиентов**. Для каждой подход описываются идея и типы рекомендаций,
модель и признаки, стратегии обучения, данные и инструменты, метрики, организация офлайн/
онлайн выдачи, представление результатов бизнесу, а также необходимые интерфейсы и
интеграции.

## Вариант 1: Персонализированная рекомендательная

## система

### Идея и типы рекомендаций

Персонализированная система стремится максимально точно подстроиться под
**индивидуальные потребности** каждого клиента. Идея в том, чтобы использовать все
доступные данные о поведении конкретного человека (транзакции, покупки, реакция на акции и
пр.) для предсказания, **какой продукт банка ему предложить следующим**. Ключевые типы
рекомендаций в этом варианте:

Next Best Offer (NBO) – определение «следующего лучшего предложения» для клиента, то
есть продукта, который с наибольшей вероятностью удовлетворит актуальную
потребность именно сейчас. Например, после получения зарплаты NBO может быть
вклад или инвестиционный продукт.
Кросс-продажи – персональные рекомендации дополнительных продуктов,
дополняющих уже используемые. Например, если у клиента активна дебетовая карта,
предложить ему кредитную карту с подходящим лимитом, страховку или инвестиционные
услуги, исходя из его профиля расходов.
Апсейл (upsell) – рекомендации на повышение категории продукта. Например,
предложить премиальное обслуживание клиенту, чьи транзакции и баланс показывают,
что он может заинтересоваться более высоким уровнем сервиса.
Персональные акции и бонусы – таргетирование специальных предложений (кешбэк,
скидки) под интересы клиента на основе его истории покупок (например, повышенный
кешбэк на категории, где клиент активно тратит средства).

Такой подход устраняет ограничения текущих механизмов маркетинга, которые грешат узким
набором фич и низкой релевантностью. Благодаря учёту тонких поведенческих паттернов из
разных источников данных система избегает «баннерной слепоты» и повышает отклик клиентов.

### Архитектура модели и используемые признаки

**Архитектура модели** в персонализированном подходе обычно **многоуровневая (ensemble)** ,
сочетая несколько алгоритмов: факторизационные методы, градиентный бустинг и нейросети.
Основная цель – научиться предсказывать отклик конкретного пользователя на различные
продукты. Возможная архитектура включает два этапа:

Многофакторная модель предпочтений. На первом этапе модель извлекает скрытые
факторы (embeddings), описывающие вкусы пользователя и характеристики продуктов.
Например, матричная факторизация разлагает матрицу взаимодействий User × Product на
эмбеддинги пользователей и продуктов. Здесь «продукт» – банковский продукт или
категория продукта. Поскольку явных рейтингов может не быть, используется
имплицитная обратная связь (например, факт покупки/непокупки продукта, клики на
оффер). Полученные эмбеддинги позволяют вычислять степень соответствия
пользователя и продукта как скалярное произведение (чем выше, тем больше
вероятность интереса). Такой факторизационный подход хорошо масштабируется на
большие данные и выявляет скрытые взаимосвязи предпочтений.
Контентно-ориентированная и признаковая модель. На втором этапе используется
модель, учитывающая явные признаки пользователя и продукта. Это может быть
градиентный бустинг (CatBoost/XGBoost) либо нейросеть Wide & Deep (смешивающая
признаки и эмбеддинги). Входные признаки включают:
Демография и профиль клиента: регион, сегмент или кластер, соц.-демо признаки из
каталога пользователей (возрастной диапазон, доходный класс и т.п., если есть), типичный
стиль расходов.
Транзакционная активность: агрегаты по платежам – средний ежемесячный расход,
остатки на счетах, частота покупок определенных категорий (путешествия, супермаркеты
и т.д.). Эти фичи помогают понять текущие потребности (например, большие траты на
авто намекают на интерес к автострахованию).
Поведение в маркетплейсе: категории товаров, которые пользователь просматривал или
покупал в e-commerce (из домена Marketplace/Retail датасета). Это косвенно указывает на
интересы – например, частые покупки детских товаров могут подсказать предложить
образовательный вклад для ребенка.
Реакция на предложения: история взаимодействия с маркетинговыми кампаниями (домены
Offers). Какие акции или баннеры привлекали внимание (клики), а какие нет – это сигнал,
какие механики или категории интересны клиенту.
История продуктов банка: какие продукты клиент уже имеет (кредиты, карты и пр.), их
параметры и давность использования. С одной стороны, не рекомендуется предлагать то,
что уже есть; с другой – можно предлагать обновление (апгрейд) или сопряжённые услуги.
Также важен жизненный цикл : например, если кредит почти выплачен, можно
предложить новый.
Временные факторы: сезонность и стадия жизненного цикла клиента. Например, перед
отпускным сезоном у подходящих клиентов повышается релевантность предложений по
кредиткам для путешествий или страховке.
Контекстные сигналы: если система работает в режиме реального времени, можно
использовать последние события (только что отклонённый платеж – предложить
овердрафт; большой приток средств – предложить инвестиции). Контекст усиливает
контекстуальную уместность рекомендаций.


Модель на этом этапе предсказывает _скоринг_ (рейтинг) для каждой пары пользователь-продукт –
условную вероятность или оценку релевантности. Благодаря богатому признаковому
пространству достигается высокая **релевантность предложений** (насколько продукт
соответствует реальной потребности) и логичность Next Best Offer с точки зрения бизнес-
правил (например, не советовать противоречащие продукты одному клиенту одновременно).

**Построение профилей.** Важной частью архитектуры является формирование профилей: каждый
клиент представлен вектором признаков и эмбеддингов, **индивидуальный профиль** с учетом
его уникальных данных. Параллельно система формирует **среднестатистический профиль
по каждому продукту** – условный “портрет” типичного клиента данного продукта. Этот
профиль продукта вычисляется как агрегированные характеристики всех клиентов,
воспользовавшихся продуктом (например, средний возраст, частые категории трат, поведение до
подключения продукта). Сопоставляя профиль конкретного клиента с профилями продуктов,
легко увидеть, на какой продукт он больше всего «похож». Такой подход помогает в холодном
старте и интерпретации: бизнесу можно объяснить рекомендацию тем, что _«клиент по своим
параметрам близок к портрету пользователей продукта X»_. Профиль продукта выступает
своеобразным **эталоном** для подбора Next Best Offer.

**Адаптация к поведению.** Персонализированная модель должна быть **адаптивной** : быстро
реагировать на изменения в поведении клиента. Технически это достигается несколькими
способами: - В модели учитываются **временные веса** – последние действия получают больший
вес при расчете признаков. Например, рост расходов в новой категории в последние 2 месяца
существенно повышает значимость связанного предложения. - Регулярное обновление профиля:
при поступлении новых данных (новые транзакции, клики) пересчитываются агрегаты и, при
необходимости, эмбеддинги пользователя. Это может происходить ежедневно (batch
обновление) или практически в реальном времени (streaming обновление признаков). -
Использование модели последовательностей: дополнительно может применяться рекуррентная
нейросеть или трансформер, который прогнозирует «следующее действие/нужду» на основе
последовательности событий пользователя. Такой последовательный предиктор улучшит Next
Best Offer, улавливая сложные паттерны (например, последовательность: _поиск товара → покупка
дорогого товара → остаток средств падает_ может означать потребность в кредите). -
**Исключение нелогичных рекомендаций.** В правила бизнес-логики закладываются
ограничения, предотвращающие абсурдные либо конфликтующие предложения. Например, не
рекомендовать ипотеку студенту с минимальными доходами, или кредитку с лимитом,
превышающим обороты клиента. Эти проверки могут быть реализованы как слои фильтрации
результатов модели.

### Стратегии обучения и переобучения моделей

Обучение персонализированных моделей проводится поэтапно с учётом огромного объёма
данных и кросс-доменности:

Первичное обучение (с нуля). На старте используются накопленные исторические
данные. Например, берутся за несколько лет данные T-ECD , из них формируются
положительные примеры (клиент воспользовался продуктом или откликнулся на оффер) и
отрицательные (проигнорировал или случай из контрольной группы). Модели
факторизации (ALS, word2vec для последовательностей и пр.) обучаются на имплицитных
взаимодействиях, а модели прогнозирования (бустинг, нейросеть) – на задаче
классификации/ранжирования. Для ускорения можно выбрать T-ECD Small (~1 млрд
событий) на этапе прототипа, а затем масштабироваться на полный набор.

Transfer learning и пре-тренинг. Благодаря кросс-доменным данным можно применить
transfer learning. Например, сначала обучить нейросеть-световой автокодировщик
(autoencoder) на задаче восстановления паттернов покупок или кликов (без надзора) – это
создаст богатое представление (embeddings) пользователей и брендов в экосистеме. Затем
эти эмбеддинги использовать как готовые признаки для модели рекомендаций банковских
продуктов. Также можно предварительно обучить двухбашенную модель (two-tower) для e-
commerce рекомендаций , а затем дообучить ее башни под домен банковских офферов
- получая перенос знаний о связях товаров и предпочтений на финансовые продукты.
**Мультизадачное обучение.** Ещё одна стратегия – совместное обучение модели сразу на
нескольких целях. Например, единая нейросеть может одновременно предсказывать
вероятность покупки в маркетплейсе и вероятность отклика на банковский продукт.
Общие слои сети будут выучивать универсальные представления пользователя, полезные
для обоих доменов, что повысит качество при недостатке целевых данных по редким
продуктам. Кросс-доменная согласованность идентификаторов в T-ECD (один user_id и
brand_id во всех сервисах) позволяет легко объединять данные.
**Инкрементальное обновление.** После запуска системы важна регулярная донастройка.
Варианты:
_Batch retraining:_ переобучение моделей полностью раз в заданный период (например, раз в
неделю или месяц) на всех данных, включая свежие. Это обеспечивает актуальность, но
требует ресурсов и может запаздывать.
_Online learning:_ настройка моделей на лету при поступлении нового события. Для этого
подходят алгоритмы, поддерживающие partial_fit (например, онлайн-регрессии или
библиотека Vowpal Wabbit) или специальные подходы как **ALS-WRMF** с периодическим
пересчетом факторных embeddings для новых данных. Например, алгоритм Swing (от
Alibaba) обновляет сходства item-item инкрементно при каждом новом взаимодействии,
вместо пересчета с нуля.
_Fine-tuning:_ комбинированный подход, когда базовая модель (например, эмбеддинги)
обновляется реже, а верхнеуровневый классификатор дообучается чаще на новых
примерах.

```
Контроль переобучения: при каждом обновлении важно контролировать метрики на
отложенной выборке или через скользящее окно, чтобы модель не деградировала из-за
изменения распределения данных.
```
```
Механизмы адаптации и exploration. В продуктивной среде можно внедрить элементы
reinforcement learning или bandit-алгоритмов, чтобы адаптироваться к реакции
пользователя. Например, если пользователь игнорирует несколько рекомендаций подряд,
алгоритм Upper Confidence Bound (UCB) или Thompson Sampling может подмешивать более
разнообразные офферы (exploration) для сбора сигналов, постепенно подстраиваясь под
явные интересы. Это снижает риск застрять на нерелевантных прогнозах и повышает
долгосрочный uplift (прирост откликов).
```
### Пайплайн данных и выбор технологий

Персонализированная система требует надежного **data pipeline** – от сбора разнотипных данных
до выдачи рекомендаций. Ниже описаны основные этапы и инструменты (в скобках – открытые
технологии, применимые на каждом этапе):

Сбор и поступление данных. Необходимо интегрировать несколько источников:
транзакции, покупки, просмотры, отклики на кампании и т.д.. В реалиях банка
входящие данные могут идти как стрим событий (например, событие покупки в

маркетплейсе, транзакция по карте) или приходить пакетами из хранилищ. Лучшим
решением для объединения потоков является Kafka – распределенный брокер
сообщений, способный обрабатывать тысячи событий в секунду. Каждое событие
(например, JSON с полями user_id, время, тип действия, сумма, item_id и пр.) публикуется в
соответствующий топик Kafka (payments, marketplace, etc.). Kafka обеспечит буферизацию и
доставку с низкой задержкой, а также объединение разных источников клиентских
данных. В качестве альтернативы (при меньших нагрузках) можно использовать
RabbitMQ, но Kafka предпочтительнее для больших потоков данных.
Хранение «сырых» данных (Data Lake). Для надежности все поступающие данные
складываются в озеро данных, чаще всего на HDFS или облачное хранилище (S3). Здесь
уместно хранить в формате Parquet по датам (как и опубликован датасет T-ECD ) – это
обеспечивает сжатие и удобство дальнейшей обработки. Доступ к озеру может
организовать Apache Hive или Spark для SQL-запросов по большим данным.
Обработка и очистка данных. Далее, необходим ETL для приведения данных к удобному
виду. Этапы включают очистку (удаление дубликатов, явно ошибочных записей),
преобразования (например, парсинг категорий товаров, анонимизация, объединение с
референсными справочниками). Для масштабной обработки 135 млрд событий
используется Apache Spark – распределенная система, способная за счет параллелизма
обработать терабайты данных. Пакетные джобы Spark (или PySpark ) выполняют
агрегирование транзакций по пользователям, расчёт признаков, генерацию “сессий” и пр.
Например, можно вычислить таблицу «user_features_daily» с суммами расходов, числом
разных брендов, категорией максимальной траты за день и т.п. Также Spark удобен для
расчета эмбеддингов методом ALS или для подготовки последовательностей действий.
Feature Engineering и формирование профилей. На этом этапе происходит слияние
данных разных доменов по user_id и item_id. Собранные признаки могут храниться в
feature store – специализированном хранилище признаков. В качестве feature store часто
используют ClickHouse – колонночную СУБД, которая очень эффективна для агрегатных
запросов и может служить одновременно и офлайн хранилищем, и (при необходимости)
источником фич в режиме реального времени. В ClickHouse можно поддерживать
актуальную таблицу профилей пользователей, обновляемую ежедневно (или чаще) из
Spark. Например, колонки: user_id, сегмент, 100+ количественных признаков (средний чек,
дисперсия трат, давность последней транзакции по категориям и т.д.), и даже вектор-
эмбеддинг пользователя (хранящийся как массив чисел). Для обеспечения
согласованности между обучением и инференсом можно использовать Feast – open-source
feature store, который интегрируется с популярными хранилищами (в т.ч. поддерживает
ClickHouse) для материализации фич.
Обучение моделей. Подготовив датасеты признаков, запускаем ML-обучение. Для
управления экспериментами подключается MLflow – логирование параметров моделей,
версий данных, метрик на валидации. Обучение может выполняться распределённо
(например, Spark MLlib для ALS или XGBoost на Yarn), либо на отдельном сервере с GPU для
нейросетей (PyTorch/TensorFlow). В случае нейросетевой модели (скажем, два башни +
DLRM-ранжировщик) – можно использовать фреймворк PyTorch Lightning для удобства
тренировки. Результат – обученные модели или таблицы с предрассчитанными
рекомендациями.
Оркестрация и автоматизация. Чтобы весь пайплайн работал регулярно, применяют
Apache Airflow (или ее аналог, например Prefect) для планирования задач. В Airflow
настраивается DAG: ежедневный запуск ETL Spark, затем обновление feature store, затем
обучение/обновление модели, затем развертывание модели или расчёт топ-
рекомендаций. Airflow следит за зависимостями и выполняет шаги по расписанию или при
поступлении новых данных (через сенсоры Kafka, например).

Деплоймент и выдача рекомендаций. Обученную модель необходимо использовать
для выдачи рекомендаций клиентам. Два подхода: (а) офлайн предрасчет – модель
вычисляет топ-N рекомендаций для каждого пользователя заранее (batch inference) и
сохраняет их, например, в Redis или в ту же ClickHouse (таблица user_id ->
[рекомендуемые продукты]). (б) онлайн вывод – развернуть модель как сервис,
который по запросу выдает рекомендации на лету. Для онлайн сервинга подойдет HTTP
API сервис (например, на FastAPI или gRPC ) внутри Docker-контейнера. Если модель –
нейросеть, можно использовать TensorFlow Serving или NVIDIA Triton для
высокопроизводительного вывода. Также рассматривается гибридный вариант:
предварительно отобрать кандидатов офлайн, а финальный re-ranking делать онлайн под
текущий контекст.
Мониторинг и логирование. В продуктиве важно мониторить качество и
работоспособность. Логи событий (какие рекомендации показаны, какие приняты) снова
собираются через Kafka в хранилище. На их основе метрики модели контролируются:
например, с помощью EvidentlyAI или собственных дашбордов строится динамика
Precision@K, конверсии, выявляется дрейф признаков. Инфраструктура (серверы,
задержки) мониторится через Prometheus + Grafana.
Выбор технологий может варьироваться, но перечисленные инструменты – открытые и
проверенные временем решения, которые обеспечат **масштабируемость и
производительность** пайплайна. Например, ClickHouse способен обработать аналитику по
миллиардам строк практически в реальном времени, а Kafka гарантирует надёжную доставку
данных даже при всплесках нагрузки.

### Метрики оценки и примеры user story

Эффективность рекомендательной системы оценивается по нескольким группам метрик:
качество ранжирования, бизнес-метрики и каузальные метрики. Рассмотрим ключевые и
приведем пользовательские сценарии (user stories) для иллюстрации:

Precision@K (Точность на K): доля рекомендованных элементов в топ-K, которые
оказались релевантными для пользователя. В контексте банка релевантность может
означать, что клиент проявил интерес или оформил продукт. User story: Приложение
показало 5 персональных предложений (K=5), из них 2 действительно заинтересовали
клиента (он кликнул и оставил заявку). Precision@5 = 40%. Чем выше эта доля, тем менее
«пустых» рекомендаций видит клиент. Высокий Precision@K свидетельствует, что система
отфильтровывает нерелевантные офферы и пользователь не испытывает
информационного шума.
NDCG (Normalized Discounted Cumulative Gain): метрика ранжирования, учитывающая
порядок выдачи. Она отражает, насколько высоко в списке расположены наиболее
релевантные для пользователя объекты. Проще говоря, большой вес придается тому,
чтобы самые ценные рекомендации были показаны первыми. User story: Двум разным
клиентам система выдала по 3 рекомендации. У обоих в подборке есть 1 очень
подходящий продукт и 2 средней релевантности. Однако у первого клиента самый
полезный продукт стоит на первом месте, а у второго – на третьем. Несмотря на
одинаковое число релевантных предложений, NDCG у первой выдачи выше, так как
важный совет дан сразу. Метрика NDCG хорошо отражает соответствие рекомендаций
ожиданиям пользователя – в нашем случае первый клиент сразу видит нужный
продукт и с большей вероятностью воспользуется, чем второй, которому пришлось бы
«прокручивать» менее актуальные варианты.

Uplift (Прирост конверсии): показатель бизнес-эффекта от рекомендательной системы.
Измеряется путем A/B-теста: сравнивается группа клиентов, получающих персональные
рекомендации, с контрольной группой без них (или с текущим простым подходом). Sales
uplift – насколько увеличился инкрементальный процент продаж/оформлений продукта
благодаря системе. User story: 10000 клиентов были разделены случайно на 2 группы.
Первая получала новые AI-рекомендации в течение месяца, вторая – только стандартные
рассылки. В итоге в первой группе 500 клиентов открыли новые продукты, а в
контрольной – только 300. Конверсия выросла с 3% до 5%, uplift = ~+66%. Это прямое
доказательство ценности системы в денежном выражении. Uplift считают отдельно по
каждому продукту и в целом, выявляя где рекомендации дали максимальный эффект.
Важно: uplift показывает дополнительный результат именно от таргетирования,
очищенный от внешних факторов, благодаря контролю.
Конверсия (Conversion Rate): доля пользователей, принявших рекомендации. В отличие
от uplift (который фокусируется на разнице с контролем), абсолютная конверсия просто
показывает, скольким из охваченных рекомендациями клиентов продукт оказался
интересен. User story: Из 100 клиентов, которым приложение предложило кредитную карту,
8 оформили её – конверсия 8%. Данная метрика удобна для отслеживания в реальном
времени и по каналам (мобильное приложение, веб, офис). Рост конверсии в ключевые
продукты – одно из ожидаемых результатов системы.
Дополнительные метрики:
Recall@K (полнота на K): доля всех релевантных продуктов, которые удалось
порекомендовать в топ-K. Например, если клиенту потенциально интересны три продукта,
а система из них показала два – Recall частично отражает охват интересов. Однако для
Next Best Offer приоритеть именно precision (лучше одно точное предложение, чем пять
“на всякий случай”).
CTR (click-through rate): отношение числа кликов на рекомендованный баннер/офер к числу
показов. Полезно для оценивания вовлеченности: высокий CTR значит, что заголовки/
тексты рекомендаций цепляют внимание, и подборка выглядит уместной.
Retention uplift: влияет ли система на удержание клиентов. Это более долгосрочная метрика
- например, сравнить долю «спящих» клиентов, вернувшихся к активности, среди тех,
кому направлялись персональные кампании.
_Средний доход на клиента:_ можно измерять LTV (Lifetime Value) до и после внедрения
рекомендаций, или средний чек клиента, чтобы увидеть, увеличились ли продажи cross-
sale продуктов.

Каждая метрика отвечает на свой вопрос: точность и NDCG – насколько хорошо мы угадываем
потребности конкретного пользователя; uplift и конверсия – какую выгоду это приносит бизнесу;
retention и удовлетворенность – как это влияет на долгосрочные отношения с клиентом. Эти
показатели используются и при оценке качества решения в AI Challenge, чтобы
продемонстрировать и техническое качество, и бизнес-ценность.

### Онлайн vs офлайн рекомендации: организация выдачи

Рекомендательная система может работать в двух режимах: **офлайн (batch)** генерация
рекомендаций и **онлайн (real-time)** генерация. Оба подхода можно комбинировать, но важно
понимать отличия.

_Пример архитектуры офлайн-пайплайна:_ Модель кандидатов (двухбашенная) и ранжирования
(например, DLRM) офлайн генерируют рекомендации, которые сохраняются в хранилище (Redis)
для быстрого доступа. Такой batch-подход удобен для периодического обновления
рекомендаций, например, раз в сутки.

**Оффлайн (batch) рекомендации.** В этом случае все вычисления происходят в фоновом режиме
без запроса пользователя. Как показано на схеме выше, система выполняет полный цикл: сбор
свежих данных -> пересчет модели -> генерация списка Top-N продуктов для каждого клиента ->
сохранение результатов. Например, каждую ночь обновляется таблица «Top 3 предложения для
пользователя X». Хранилищем может служить быстрый key–value store (Redis, Tarantool) или
колонночная БД (ClickHouse) – в любом случае, фронтенд затем может забирать готовые
рекомендации по user_id с минимальной задержкой (несколько миллисекунд).

**Преимущества офлайн подхода:** - Можно использовать тяжелые модели и очень сложные
фичи, не беспокоясь о времени ответа – расчеты идут задолго до момента показа. Например,
можно прогнать весь 44-миллионный набор пользователей через нейросеть и это займет
несколько часов офлайн, что приемлемо. - Рекомендации могут быть сразу проверены на
предмет бизнес-правил, откорректированы вручную (например, маркетинг может заложить, что
в ближайшую неделю всем футбольным фанатам обязательно показать оффер партнера
чемпионата). - Проще обеспечить стабильность: если сервис рекомендаций временно
недоступен, у фронта остаются последние загруженные списки.

**Недостатки офлайн:** неучет мгновенного контекста и реактивности. Если клиент час назад
выполнил какое-то важное действие (например, открыл вклад), до следующего обновления он
может получать устаревшие советы (например, система продолжит предлагать вклад, который
уже открыт). Для смягчения, можно увеличить частоту обновлений (скажем, каждый час) или
комбинировать с онлайн.

**Онлайн (real-time) рекомендации.** Здесь подразумевается генерация на лету: когда
пользователь открывает приложение или заходит в личный кабинет, система тут же
рассчитывает для него персональные предложения. Это требует развернутого сервиса, который
способен за <100–200 мс сформировать рекомендацию по актуальным данным.

_Пример архитектуры онлайн-пайплайна:_ Многоэтапный конвейер в реальном времени (retrieval -
> filtering -> scoring -> ordering) исполняется как ансамбль моделей внутри сервиса (например,
NVIDIA Triton), с доступом к feature store (Redis/Feast) для актуальных признаков. Онлайн
система может динамически учитывать новые события (последние клики, изменения баланса и
пр.) при расчете Next Best Offer.

**Особенности онлайн подхода:** - **Низкая задержка** – критический фактор. Используются
оптимизированные модели и методы: быстрые lookup признаков (например, хранить последние
агрегаты в памяти), возможно приближенные методы поиска (ANNS – Approximate Nearest
Neighbors) для эмбеддингов, чтобы мгновенно получить похожие пользователей или items. В
приведенной схеме, например, этап _Retrieval_ может использовать FAISS или RedisSearch для
поиска топ-N кандидатов по эмбеддингу пользователя. - **Статус в реальном времени.**
Модель видит самые последние действия. Например, если клиент только что положил крупную
сумму на счет, онлайн-алгоритм тут же отреагирует и предложит инвестиции. Это обеспечивает
**контекстуальную уместность** рекомендаций , повышая шансы на конверсию. - **Сложность
инфраструктуры.** В отличие от офлайн, здесь нужен постоянно работающий сервис, способный
масштабироваться под число запросов пользователей. Часто применяют контейнеризацию и
оркестрацию (Kubernetes) для автамасштабирования под нагрузку (например, в пиковые часы
интернет-банка). Также нужен продуманный **кеш** : если одни и те же рекомендации требуют
тяжелого вычисления, их можно кешировать на короткое время (несколько минут) на случай
повторных запросов. - **Многоэтапный конвейер.** В реальном времени можно разбить задачу на
стадии: быстрая предварительная выборка кандидатов (например, 50 потенциально интересных
продуктов) -> фильтрация (удалить уже имеющиеся у клиента продукты, дубли,


несоответствующие условиям) -> детальный скоринг топ-10 моделей (например, нейросетью
с учётом контекста) -> финальная сортировка с бизнес-правилами (например, чтобы не
показывать одновременно слишком похожие продукты). Несмотря на дополнительную
сложность, такая архитектура доказала эффективность в крупнейших компаниях.

**Комбинированный подход.** Реально в продакшене нередко сочетаются оба режима: офлайн-
предвычисление + онлайн-актуализация. Возможны варианты: - Основные рекомендации
рассчитываются офлайн, но затем _ранжируются/фильтруются онлайн_ под свежие данные.
Например, ночью система выбрала 5 лучших продуктов для клиента, а когда он заходит днём,
сервис ещё раз сортирует эти 5 с учетом последних действий (или убирает один, если за ночь он
потерял актуальность). - **Stream обновление офлайн-рекомендаций:** вместо фиксированного
расписания, pipeline запускается триггерами – как только в Kafka появляется событие, меняющее
профиль (например, клиент оформил продукт), генерируется новая рекомендация для него. Это
приближает систему к real-time, но с более простой архитектурой (т.к. расчёт всё равно
происходит в фоновом режиме, просто очень часто). - **Fallback режим:** если онлайн-сервис не
отвечает за разумное время, фронтенд может подставить ранее сохраненные офлайн-
рекомендации, чтобы не оставить пустой блок. Это повышает надежность и отказоустойчивость
решения.

При выборе подхода учитываются требования бизнеса и технические возможности. Если
критично учитывать последние секунды взаимодействия пользователя – не обойтись без online.
Если же продуктовые предложения меняются не настолько часто и можно ждать несколько часов

- batch подход проще и дешевле. **Рекомендуется внедрить систему постепенно:** начать с
офлайн-режима (быстрее разработать, меньше требований к инфраструктуре), затем по мере
повышения зрелости добавить элементы онлайн-сервинга для конкретных кейсов (например,
триггерные предложения в момент события). Это позволит банку сразу получить выгоду, а
команде – набраться опыта с данными и моделью, прежде чем строить сложный real-time контур.

### Презентация результатов бизнесу

Чтобы убедить бизнес-стейкхолдеров (менеджмент, маркетинг, продажи) в ценности новой
системы, важно **правильно презентовать результаты**. Ниже описано, какие материалы и
визуализации можно подготовить для каждой системы:

```
Показатели успеха. На первом же слайде – ключевые улучшения в метриках. Например:
«Конверсия в открытие продукта увеличена на +5 п.п. (с 3% до 8%) за счет персональных
рекомендаций», «CTR персональных офферов 20% vs 5% у контрольной группы», «Uplift в
продажах кредитных карт +30% относительно текущего подхода». Такие цифры сразу
фокусируют внимание на бизнес-выгоде. Желательно подкрепить их графиком: столбик
«до» и «после», или кумулятивная кривая ростa подключений продуктов в двух группах
эксперимента – чтобы визуально показать разницу.
A/B тестирование. Отдельным блоком – результаты экспериментов. Например, таблица
с группами, где одна получала персональные рекомендации, другая – нет, и сравнением их
показателей: количество новых продуктов, средний доход на пользователя, NPS.
Отчетливо показать статистически значимые улучшения. Для наглядности можно
использовать диаграмму uplift – график, где по оси X дни эксперимента, по Y – разница в
кумулятивных конверсиях между группами. Если кривая уверенно выше нуля –
кампания успешна.
Примеры пользовательских историй. Бизнес ценит конкретику, поэтому стоит включить
кейсы отдельных клиентов (обезличенно). Например: «Клиент А раньше имел только
дебетовую карту. Система обнаружила, что у него крупные регулярные траты на

путешествия, и порекомендовала ему карту с милями. Клиент откликнулся и оформил ее,
благодаря чему увеличил свой лимит и получил кешбэк ≈10 тыс.₽ за полгода, а банк –
клиента на премиум-программе». Еще пример: «Клиент Б не пользовался счетом 8 месяцев.
Система определила его как “спящего” и предложила персональную акцию на вклад. Клиент
вернулся и открыл вклад на 500 тыс.₽ – мы вернули его активность». Такие истории,
желательно подкрепленные цифрами, делают пользу системы понятной на уровне
индивидуального клиента.
Визуализация работы алгоритма. Показать схематично архитектуру (но не
перегружать техникой). Например, блок-схема: «Данные транзакций + поведении ->
Хранилище -> Модель -> Каналы коммуникации». Можно изобразить, как данные от
клиента превращаются в предложение. Интуитивный рисунок: фигурка человека с
разными действиями (покупка, просмотр), стрелки к «мозгу» AI, оттуда стрелка к витрине
продуктов, где выделен рекомендованный продукт. Такая схема поможет немедленно
понять принцип «собираем данные – предсказываем нужду – даем предложение».
Разбиение на сегменты (для варианта с сегментами). Если используется сегментный
подход, можно показать портреты сегментов : например, сегмент «Молодые
профессионалы»: 25–35 лет, активны онлайн, интересуются инвестициями – 40% им
рекомендованы брокерские услуги, конверсия 12%. Сегмент «Пенсионеры с
накоплениями»: 55+, предпочитают вклады – им в 60% случаев рекомендованы депозиты,
конверсия 8%. Визуально это может быть представлено в виде инфографики: на одного
персонажа-сегмента нанесены ключевые характеристики и его «Next Best Offer». Бизнесу
это зайдет, т.к. перекликается с классическим маркетинговым сегментированием.
Графики клиентского пути. Можно привести диаграмму изменения поведения клиента
после внедрения рекомендаций. Например: график количества продуктов на одного
клиента со временем – после запуска персональных офферов кривая начала расти
быстрее. Или воронку: из 100 тысяч клиентов рекомендацию увидели столько-то, кликнули
столько-то, оформили столько-то – и показать, где удалось улучшить показатели по
сравнению с прошлой кампанией (например, шире горлышко воронки на этапе интереса).
Окупаемость и ROI. Бизнес-ориентированный слайд – оценка финансового эффекта.
Например: «Дополнительный доход от продаж за 3 месяца – 50 млн ₽, при затратах на
внедрение 5 млн ₽ => ROI = 900%». Сюда же – прогноз на год : если масштабировать на всю
базу, потенциал прироста выручки N млн. Желательно указать, что учтена и экономия от
оптимизации маркетинговых рассылок (меньше спама – меньше затрат на коммуникации,
выше эффективность).
Отзыв клиента или менеджера. Если есть возможность, привести цитату
удовлетворенного клиента ( «Приложение будто читает мои мысли – все предложения в
тему!» ) или комментарий менеджера по продукту ( «Персонализация позволила нам лучше
понять потребности наших клиентов и увеличить продажи без увеличения рекламных
бюджетов» ). Это добавляет доверия и «человечности» результатам.
```
Важно, что для разных аудиторий акценты могут меняться. Высшему руководству – цифры по
прибыли и удержанию клиентов. Маркетингу – детали про сегменты, CTR, примеры креативов
персональных кампаний. ИТ-департаменту – архитектура, вопросы масштабирования и
интеграции. Поэтому презентацию можно разбить на блоки, как сделано выше, и в зависимости
от слушателей делать упор на соответствующий блок.

### API и интеграции: взаимодействие с фронтендом и данными

Для внедрения рекомендательной системы в инфраструктуру банка необходимо разработать
четкие **API и контракты интеграции** между компонентами. Основные точки взаимодействия:

API рекомендательного сервиса. Фронтенд (мобильное приложение, веб-банкинг, CRM-
рабочее место в отделении) должен получать рекомендации через стандартизированный
интерфейс. Как правило, это REST API или gRPC endpoint. Формат запроса: например,
GET /api/recommendations?user_id=12345&channel=mobile&top_k=3. Параметры
могут включать идентификатор клиента, контекст (канал, тип сессии) и количество
требуемых рекомендаций. Ответ – структурированный JSON, содержащий список
рекомендуемых продуктов с деталями:


``` {

"user_id": 12345,
"timestamp": "2025-11-27T20:51:00Z",
"recommendations": [
{"product_id": "CC_Gold", "product_name": "Золотая кредитная
карта", "score": 0.85},
{"product_id": "Loan_Car", "product_name": "Автокредит", "score":
0.60},
{"product_id": "Inv_Bonds", "product_name":"Облигации
(инвестиции)", "score": 0.50}
]
}
```
Тут score – необязательное поле релевантности (можно не показывать клиенту, но
использовать на фронте для ранжирования/фильтрации). Контракт такого API должен
быть документирован: какие продукты возможны (справочник), гарантия, что не будут
рекомендованы запрещенные сочетания, время жизни рекомендаций (например,
рекомендации обновляются не реже чем раз в N часов). Также оговаривается поведение
при отсутствии данных (cold start) – например, API может вернуть наиболее популярные
продукты в сегменте клиента.
API для обратной связи. Чтобы система училась и адаптировалась, нужно собирать
отклики. Реализуется дополнительный метод, например POST /api/recommendations/
feedback, куда фронтенд отправляет события: клик по рекомендации, скрытие/дизмисс
предложения, покупка продукта (если известно в режиме реального времени). Эти данные
поступают в хранилище логов и далее через пайплайн (Kafka -> обработка) идут в модель
для дообучения. Контракты таких событий подробно описываются (event_type, rec_id,
user_id, timestamp и пр.).
Интеграция с системами данных. Рекомендательная платформа должна получать
обновленные данные о клиентах: транзакции, список уже принадлежащих продуктов,
ивенты из цифровых каналов. Здесь возможны два подхода: (1) Чтение из операционных
баз/CRM – например, ежедневный экспорт из core banking по клиентам (CSV/партиции),
или online-вызовы API других систем (менее предпочтительно из-за нагрузки). (2)
Интеграция через шину данных – вenterprise-среде часто используется Kafka как основной
брокер событий. В таком случае, команды разработки смежных систем договариваются о
формате сообщений. Пример: топик bank.transactions с событиями транзакций (fields:
account_id, amount, merchant_category, ...), топик bank.product_events с событиями
оформления/закрытия продукта. Контракты данных должны гарантировать

неизменность схемы или её версионирование – чтобы наша система не «упала» при
добавлении нового поля. Хорошей практикой будет Protobuf или Avro-схемы для
сообщений Kafka, согласованные заранее.
Обогащение профилей из DWH. Некоторые данные нужны модели, но не генерируются
оперативно. Например, признак кредитного рейтинга клиента или его давность
отношений с банком. Эти данные могут браться из Data Warehouse (хранилище) с
задержкой. Для интеграции планируется периодическая выгрузка необходимых атрибутов
клиентов из DWH (например, таблицы CRM) и загрузка в feature store. Это реализуется либо
скриптом ETL (в Airflow, ежедневный джоб), либо через streaming, если DWH поддерживает
CDC (change data capture). Контракт здесь – описание атрибутов, их типов, периодичности
обновления, а также ответственность за качество данных (отдел данных должен, к
примеру, гарантировать, что поле «доход сегмент» заполнено > 95% клиентов и
обновляется ежеквартально и т.п.).
Интерфейсы с маркетинговыми каналами. Помимо digital-каналов, банк может
использовать рекомендации в рассылках, колл-центре, банкоматах. Например, для email-
рассылки система каждое утро может генерировать свежие топ-оферы для сегмента
клиентов и складывать в таблицу, откуда их берет маркетинговая платформа. Это
интеграция «через базу»: т.е. наша система обеспечивает, что в таблице daily_offers
всегда актуальные 3 предложения для каждого клиента. Маркетинг-система (например, SAS
RTIM или отечественный аналог) по API или SQL берет оттуда контент для писем. Контракт
```
- структура таблицы, время готовности данных каждый день, соглашение о fallback (если
на кого-то нет персонального совета – что подставлять).
**Безопасность и доступы.** Так как речь о банковских данных, все API должны быть
защищены. Обычно используется аутентификация сервис-сервис через OAuth2 или mTLS.
Контракты интеграции должны включать требования по шифрованию (например, канал
Kafka – в VPN или SSL), маскирование PII (все перс.данные уже анонимизированы в T-ECD,
но в бою реальный user_id – это защищаемая информация, должны использоваться
внутр.идентификаторы или токены). Также оговариваются SLA: например, API
рекомендаций должен отвечать ≤100 мс 95% запросов, доступность 99.5%.

**Брокеры данных.** Уже упоминался Kafka как центральный. В дополнение можно упомянуть, что
если банк использует корпоративную сервис- шину (ESB) или очереди типа RabbitMQ для
синхронных взаимодействий, то наша система может подписаться и на них. Но с учетом объема
и скорости событий, Kafka более масштабируемый вариант. RabbitMQ может пригодиться для
точечных задач – например, отправить событие в реальном времени в фронтенд (через
вебсокет) о появлении нового предложения. Но это частный случай; основная шина – Kafka.

**Версионирование моделей и API.** Следует определить контракт для деплоймента новых версий
модели. Например, REST API v1 выдаёт рекомендации моделью v1. Когда обучена новая модель
v2, мы развертываем её на новый endpoint (или с флагом версии). Фронтенд может постепенно
переключиться, либо трафик разделяется для A/B теста новой модели. Это важно, чтобы
избежать ситуаций, когда новая модель ведет себя непредсказуемо – всегда должен быть откат
на предыдущую версию. MLflow может помочь как модельный реестр – хранить разные версии и
иметь возможность быстро переключать.

Наконец, интеграция с инфраструктурой ПСБ требует **готовности к продакшн-внедрению**.
Наша система должна быть **масштабируема** (горизонтально масштабируемые сервисы,
распределенное хранилище), **отказоустойчива** (кластер Kafka, репликация БД, fallback
механизмы) и легко встраиваться в существующий стек. Предложенные открытые технологии
(Airflow, Spark, Kafka, ClickHouse и др.) достаточно гибки, чтобы их можно было развернуть on-
premises или в облаке банка. В совокупности, продуманная API-ориентированная интеграция и

надёжная архитектура обеспечат бесшовное внедрение рекомендательной системы в цифровые
каналы ПСБ, что позволит в полной мере реализовать **монетизацию данных** и повысить
удовлетворенность клиентов, как того ожидает бизнес.
